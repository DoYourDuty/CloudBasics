### Cloud Presence & Privacy
Security and privacy are major concerns in cloud computing. Discover the importance of understanding the presence and privacy factors when conducting business in the cloud.

### Table of Contents
- Presence Information Overview
- Presence System Components
- Presence Process and Tools
- Presence Security
- Cloud Privacy Concerns
- Privacy Policies
- Data Life Cycle
- Data Security Challenges
- Mapping Security Measures to the Data Life Cycle
- Exercise: Controlling Access to Cloud Data

### Presence Information Overview
In this video, I'll do an overview of presence information. Because most of today's work force is always available, thanks to mobile devices, there's always a need to know if a device, a service, or a user is available in a timely fashion. Presence data stems from older Chat Client software, where we could see if somebody was available and online. Presence data allows us to deploy real-time services that ends up improving productivity. And one of the reasons for that is because we have a reduction of time before we wait to see if somebody is available, or responds, or answers, a business-related question. So this also means that we could potentially achieve greater revenue. Presence data is dependent upon network availability, where we can detect users or other devices to see whether they're available or not. The purpose is to signal availability for interaction over a network, whether that's a 3G or 4G cellular type of network or over the Internet.

So we can look at the availability of things like phones, applications, routers, or any type of web-based service. Attributes associated with this type availability would include a mood. So a user might set a mood, or a location, as per GPS coordinates perhaps, or even the city name, and even the preferred method of communication. Now if you think about what we might see often on the Internet, in the case of social networking sites like Facebook, we can see who's online. We could often see how they're connected, such as from a mobile device, and if configured when someone posts a Facebook status update, we can see where they were when they posted it. This is all related to presence information. Presence protocols include a way to discover services and their availability. This way applications as well as devices can exchange information back and forth. It's automated so there is no human involvement required for the presence information to be determined.

There are frameworks that have been produced by organizations such as the IETF, the Internet Engineering Task Force, to facilitate standards for this service discovery. There are also other standard such as the XML Messaging Presence Protocol, or XMPP, that is used to present presence information. In this video, we discussed presence information.

### Presence System Components
In the cloud environment, presence allows us to determine the availability of an individual, a group of users, a device, or an application. The identity is referred to as the user's presentity. Presentity could also refer to a group, such as in the case of call center agents. The presentity is the entity that's being targeted in terms of presence state. There can also be location information provided that informs others how and where to contact somebody. Another component of a presence system is the status of the entity. This will refer to the user's levels of availability so this way others could determine whether someone is available to communicate and in what context. Some examples of statuses include somebody being online, or offline, or away and many different applications will use a host of other statuses. Devices that broadcast or publish presence data can also display a graphical indicator with the list of text options describing each of those statuses. Another presence system component is location. This refers to the geographical location of a device or some kind of entity.

Now this also is important because we can determine which computer or device a user is accessing. So from an auditing or tracing point of view, this could be useful. But from a security or privacy point of view, this could be disconcerting if it's not being used appropriately. Many applications will have an option where location awareness can be turned off if required. Location information can include geo-location type of data, such as GPS coordinates. Also, availability information is made available to users connected to the network, where we can determine if they're in a meeting, at their desk, in traffic, at home. Now those don't have to necessarily be set manually by the user. So we could have application software that detects the location of a user perhaps based on their GPS coordinates or if they're moving or not, and can change their status accordingly for others to see. In this video, we discussed presence system components.

### Presence Process and Tools
In this video, I'll discuss presence process and tools. Presence is one of the many benefits of using cloud services, whereby we can identify users, devices, or services and their availability. The Session Initiation Protocol, or SIP, is a signaling protocol that was designed by the Internet Engineering Task Force, IETF, and it controls multimedia communication sessions that typically take place across one or more media streams. Examples of SIP usage include video conferencing, multimedia streaming, instant messaging, presence information, and multimedia file transfers. So if you think about commonly used social networking tools like Facebook, Skype, FaceTime among many others that show us if somebody is online and perhaps even their location. The Session Initiation Protocol can leverage extensions that give presence capabilities. So this comes in the form then of an add-on to SIP-enabled applications. This way we can leverage presence in the cloud. This in turn facilitates real-time, immediate, and bidirectional communication among all cloud users, who can be located and identified.

The Extensible Messaging and Presence Protocol (XMPP) is a messaging protocol used for presence, and it's based on XML. XML is a standard format for information exchange between systems. XMPP was originally designed to support real-time communication between devices using instant messaging. But it's been expanded to support many more uses including Voice over IP. The only thing we have to consider that could be a disadvantage when it comes to presence being available in applications is privacy or security. Do we really want everyone that's using a cloud-based application to be identified with GPS coordinates? Sometimes that's appropriate, but in other cases, it may not be. In this video, we discussed presence process and tools.

### Presence Security
In this video, I'll discuss presence security. Presence-enabled systems are convenient because they provide up-to-date information about an entity on a network, such as its availability, its status, and so on. But at the same time, we need to control the amount of presence information that subscribers are allowed to view. A presence-enabled cloud has various sources that can publish presence information to a presence server. These include things like wireless devices, phones, applications, even GPS-enabled devices including vehicles. We need to ensure that we've implemented security measures to ensure the confidentiality and the integrity of personal information, such as meeting schedules, office locations, contact information, even GPS coordinates pinpointing the location of a person. Because if this information gets in the wrong hands, if it's accessed by a malicious user, it could compromise user privacy, organizational security, or even worse it could affect the safety of a user that's in a remote location, for example. Confidentiality ensures that only the authorized parties can see the presence information, whereas integrity ensures the trustworthiness of the presence information itself.

To secure a presence-enabled system, we need to make sure that presence sources like smartphones or web apps are authenticated before they can update an entity's presence information. That authentication might occur, for example, from a smartphone, where we've issued a unique PKI certificate and installed it on the phone. Without the PKI digital security certificate, the phone would not be able to authenticate to a presence-enabled system. We should also make sure that only a presentity can create and modify its own privacy rules as well as privacy filters. We could also have that configured centrally for a large number of users through a policy. Confidentiality and integrity of presence information and privacy filters can be maintained centrally by administrators. Administrators need to ensure that presence information watchers or even applications because it could be an untrustworthy application that was installed on a mobile device from an app store. We need to make sure that watchers and apps can subscribe to presence information only after they've been successfully authenticated to the presence system.

So that means that the watcher or the application would have to provide some kind of authentication mechanism, whether it's a secret phrase or a keyword, to authenticate themselves. We also want to make sure that watchers of presence information, which includes applications, are authorized based on privacy filter rules of a presentity that they're watching. So for example, GPS location information might be blocked in a privacy filter, but the other information may not be. We should also ensure that watchers and applications can obtain presence information based on the presentity's privacy filter only if they've been authorized first. In this video, we discussed presence security.

### Cloud Privacy Concerns
In this video, I'll talk about cloud privacy concerns. By far the biggest issue many organizations and individuals face when thinking about moving services or data to the cloud is privacy and security. Privacy is defined as the ability of an individual or a group of individuals to seclude themselves or information about themselves and only reveal themselves selectively. With data privacy, we need to distinguish between data privacy and information security because data privacy is not a subset of information security. And it shouldn't be considered exclusively the responsibility necessarily of the IT department. Working with specific types of data might be flagged with additional metadata by users of a system. Cloud service providers may be able to provide better privacy for data than a small or medium-sized organization can do, where they have limited IT resources. Cloud service providers have the economies of scale on their side. So they are in the business of hosting this information and services in a secured way. The reputation depends upon it.

Privacy of data remains till today a critical concern for organizations considering cloud computing. One of the reasons is because we can never be 100% sure with a cloud provider physically where the data that they are hosting for us will reside. And in many cases, there are laws or regulations that determine that our data must be within national, or provincial, or state boundaries. Breaches of data privacy can have various negative consequences for an organization. It could be financial loss through fines, loss of reputation, which can be very hard to rebuild. There could also be litigation as a result of data breaches. Other cloud privacy concerns include data access, ensuring that data is secure and can't be intercepted. For example, if we're transmitting data to the cloud that's going through an Internet connection, if we're accessing it from our on-premises network, we want to make sure that that connection is secured, whether it's through HTTPS or whether we're tunneling data through a VPN connection.

We can also consider the use of shielded VMs in the datacenter of the cloud provider. A shielded virtual machine is set up, such that even datacenter administrators cannot get into the virtual machine. They can't see what processes are running. They certainly can't get to the data stored in it because it's encrypted. We should also think about compliance. There could be privacy legislation or regulations that control how data is accessed and where it is stored. We would have to look at various cloud service providers to determine if any would make that work correctly. For data storage, we have to think about keeping data private. So if we're keeping data in the cloud, then we might consider encrypting it. And that's part, as we said earlier, of shielded virtual machines encrypting data on the virtual hard disks. Then at the end of its life, we have to think about data that gets removed that was previously hosted in the cloud. Is it being destroyed effectively? We don't want another cloud tenant, for example, to be allocated some storage that we had used previously where the data was not destroyed properly.

Because, there could be data remnants that another cloud tenant, for example, or even a malicious user might be able to reconstruct. Then there's the issue of data retention. For which period of time where we retain data that's being stored in the cloud? This could be driven by industry regulations, where, for example, in the financial services industry, we have to keep records of financial transactions for a certain number of years. For auditing and monitoring, we need to make sure that privacy requirements are being met. And the only way to really do that after having set things in motion is to audit and monitor usage. We should also consider background checks for IT administrators, whether that's on-premises or in the cloud. Finally, with privacy breaches, we want to make sure that clients are informed immediately of this type of breach. Otherwise, it could result in litigation or harsher litigation than if we hadn't done it.

Now this would apply both to cloud service providers notifying cloud customers of a data breach, but also if the cloud provider has a breach, we...if we are an organization using cloud services and perhaps selling products to the public, we've got to make sure we notify our customers of our cloud providers' breach. In this video, we discussed cloud privacy concerns.

### Privacy Policies
In this video, I'll talk about privacy policies. Privacy policies outline how presence information should be used and disseminated within a presence-enabled system. At the same time, policies could also be used centrally to configure these settings and enforce them on a multitude of devices. With presence information, it needs to be selectively kept private within a cloud environment. Presence information might typically include sensitive data, such as the availability of an entity on the network or its location even down to GPS coordinates. Presence information should be distributed only to authorized watchers. A presentity, such as a cloud provider, needs to create a privacy policy document that outlines rules, and permissions, and how presence information can be distributed. The privacy policy should also outline the authorization of presence information watchers. It should define how information can be made accessible to watchers only once they've been authenticated and authorized to see specific presence information.

We should also consider selective notifications, whereby we can specify what presence information is made accessible to authorized watchers. So for example, GPS coordinate information might be tightly controlled and only made available to certain groups of watchers where appropriate, whereas status information is made available to everyone authenticated to the presence-enabled system. With differential presence information, we should differentiate between these types of information and control how it gets distributed to different groups of watchers. All of this should be listed in our privacy policy document. There can also be local and national rules that impact the sharing of presence information. For example, within a national boundary, it might be forbidden to provide location information or any other type of presence information to certain parties. We should also consider authorization of anonymous subscriptions. Anonymous subscribers could be enabled and authorized to access a presence-enabled system. This is done in some cases to hide identities in order to maintain privacy during certain types of sessions. In this video, we discussed privacy policies.

### Data Life Cycle
In this video, I'll go over the data life cycle. The data life cycle is a five-phased approach that deals with the natural progression of information from when it's initially created until it expires and eventually an organization disposes of it. The first of those five phases is the data creation phase, where information is created, perhaps daily, as part of business processes. That data could have different retrieval, retention, and security settings, and other data. Our users, for example, might even use templates as they build content and the templates would have the metadata related to security, retrieval, and retention settings. The second phase is storage, where information is stored either electronically or in hard copy format. For hard copies, we might have application forms printed on paper. For electronic, we could have e-mail messages stored on a mail server or application data stored on an application server. Now in this case, with an application server being hosted on a cloud provider's network, we might have to ensure that the datacenter where that's being hosted is within our nation's boundaries. We might be required by legislation or regulations. The third phase of the data life cycle is data use.

Organizations will share data by means of some type of distribution system, so that the data can be used where and when it's needed. This means the data could be shared and made available only on a corporate network, it could be an online transaction, it could even include compiling a report. Of course, if data is made available in the cloud, then we are opening up the possibilities for the number of users that can access that data from anywhere, anytime, using any device. The fourth phase of the data life cycle is archiving, where data will be kept secure for an extensive period of time often driven by regulations. We also need to ensure that the privacy of archived data is properly secured. This often means that archives should be encrypted. The final phase of the data life cycle is destruction, where data gets destroyed once the natural life cycle of information expires. So therefore, the data is no longer useful and it no longer needs to be retained. There are various methods to destroy data. We have to be careful that our cloud provider removes data in an appropriate way, such that there are no remnants that remain on disk. In this video, we discussed the data life cycle.

### Data Security Challenges
In this video, I'll talk about data security challenges. One of the challenges about working with data in the cloud is backup and recovery. This is normally a challenge even for on-premises systems. With cloud backups, we not only have to secure the backup once it's stored in the cloud, but also the transport of the backup as it's occurring from on-premises, if that's where the source is, to the cloud environment. That could be secured using an HTTPS transport or some kind of encrypted VPN tunnel. We also have to consider the bandwidth that needs to be available for the volume of data that we need to back up to the cloud. So there needs to be enough bandwidth and time to properly perform the backups. With data discovery, this could be required by law where that there is an assurance that relevant data can be retrieved whenever requested. Now this could be a problem if our data is stored in the cloud in a datacenter on a server somewhere that's outside of national, or state, or provincial boundaries. Another key challenge with data security in the cloud is data overlaps. We need to make sure that the cloud provider isolates data from one cloud tenant to another. This could happen through virtual machine isolation or also virtual network isolation.
Heading: Data Security Challenges.

The following data security challenges are displayed in a graphic organizer: Backup and recovery, Data discovery, Data overlaps, Data persistence, Inference and aggregation, Location, and Security.

We also have to consider the redistribution of storage and data on the cloud. We want to make sure that if a tenant's data gets wiped, then another tenant can't claim that storage space and get access to the data through data remnants. Once data has reached the end of its useful life, then it's expired and then the data has to be removed. We want to make sure in the cloud that data is removed effectively, so data remnants do not remain. We then have to think about inference and aggregation of data. There's a potential for public data stored in the cloud to overlap with sensitive data. Now this can be reduced or completely eliminated with virtual machine application or network instances being isolated from one another. We should also implement security measures to protect data from security breaches even if there is a data overlap. This could be done through proper auditing and monitoring, but we can also employ strict access controls to data to control who can get access to it.

Not only will public cloud providers give us the option of storing data in the cloud, whether for storage in use or archiving, but there's often a way to monitor resources, such as data stored in the cloud as well as applications running in the cloud, to ensure that they meet our organizational security policies, which could be driven by laws or industry regulations. In some cases, there will be a requirement to determine where data is being stored in the cloud. We need to consider client contracts and license agreements to make sure that we are compliant with regulatory and legal items related to data storage. We also need to make sure that data is kept confidential. In other words, to make sure that only authorized users can get to the data that's appropriate for them to get to. This can be accomplished with encryption at both the network transmission level as well as at the level of storing data within the cloud. We also need to make sure that we think about the integrity or the trustworthiness of data and its availability. Authentication of devices and users to the cloud can help ensure the integrity of data in the cloud as well as digital signatures. Digital signatures are created with the unique private key issued to an entity like a device or a user. So only that entity could have created the signature.
Heading: Data Security Challenges.

The AWS Management Console tabbed page is displayed in the Internet Explorer browser window. The page displays the multiple categories of Amazon Web Services such as Compute, Storage & Content Delivery, and Administration & Security.

The Compute category includes the following: EC2 - Virtual Servers in the Cloud, Lambda - Run Code in Response to Events, EC2 Container Service - Run and Manage Docker Containers.

The Storage & Content Delivery category includes the following: S3 - Scalable Storage in the Cloud, Elastic File System - Fully Managed File System for EC2, Storage Gateway - Integrates On-Premises IT Environments with Cloud Storage, Glacier - Archive Storage in the Cloud, and CloudFront - Global Content Delivery Network.

The Administration & Security category includes the following: Directory Service - Managed Directories in the Cloud, Identity & Access Management - Access Control and Key Management, Trusted Advisor - AWS Cloud Optimization Expert, CloudTrail - User Activity and Change Tracking, Config - Resource Configurations and Inventory, CloudWatch - Resource and Application Monitoring, and Service Catalog - Personalized Catalog of AWS Resources.

The presenter points at the following: the Elastic File System - Fully Managed File System for EC2 that is displayed under the Storage & Content Delivery category and the CloudWatch - Resource and Application Monitoring that is displayed under the Administration & Security category.

The signature gets verified on the other end of a connection using the mathematically related public key. The Service Level Agreement, or SLA, between a cloud customer and a cloud provider can stipulate guaranteed uptime for cloud IT services as well as response times. In this video, we discussed data security challenges.

### Mapping Security Measures to the Data Life Cycle
In this video, I'll talk about how to map security measures to the data life cycle. Organizational security policies, which are often influenced by laws or even industry regulations, can serve as a model depicting how data can be securely managed throughout its useful life. This starts with creation, where we have the option of classifying and identifying data as it becomes available. This can be done within specific applications either manually by the user creating the content or sometimes automatically through templates that are used to build the content. Essentially, we are adding metadata to the data that we're creating. This way we might even tag users to help classify and associate users with relevant data. For example, we might tag certain types of data as human resources and that would then be applicable to users that work in the Human Resources Department. We also have to consider enterprise Digital Rights Management, or DRM. Digital Rights Management is one way that we can prevent data leakage outside of the corporation, whereby we can digitally sign and encrypt data that users create, we can also determine whether that data can be shared through social media or instant messaging, whether it can be copied, printed, forwarded through e-mail, and so on.
Heading: Mapping Security Measures to the Data Life Cycle.

The following Data Life Cycle stages are displayed in a graphic organizer: Creation, Storage, Use, Archiving, and Destruction.

In the storage phase of the data life cycle, at the security level, we need to think about identifying sensitive data versus non-sensitive data, and then, of course, tracking use or auditing that data use. We can also implement access control mechanisms to determine which user groups, or services, or devices have access to different types of data. We should also consider the use of data encryption for confidentiality. If we're using a Database Management System, or DBMS, then it will have its own security mechanisms that we potentially could put into place. When data is in the useful part of its life, we need to carefully monitor that data usage and application activity. That can be done by looking at log files, where we might configure triggers that send us alerts or notifications. We should also consider applying object-level controls to data such as files, folders, even records in a database. We should also think about our data management solutions that might have those options already available. Most cloud providers will allow us to monitor or manage our cloud services, where we can look at logs and run queries against specific service logs,
The Management Services tabbed page is displayed in the Internet Explorer browser window. The page includes the following options in the left: NETWORKS, TRAFFIC MANAGER, REMOTEAPP, MANAGEMENT SERVICES, ACTIVE DIRECTORY, MARKETPLACE, STORSIMPLE, and SETTINGS. The MANAGEMENT SERVICES option is selected and consequently in the right the management services page is displayed. The page includes the ALERT and OPERATION LOGS tabs. The OPERATION LOGS tabbed page is active and includes the following drop-down list boxes: SUBSCRIPTION, FROM, TO, STATUS, TYPE, and SERVICE NAME.

or we can take a look at alerts or even configure alert thresholds for specific types of services that we're using from the cloud provider. When data is no longer useful, it might need to be archived or retained for a period of time before it gets removed permanently. We should consider providing data encryption for storage media, whether it's on-premises, in the cloud, or even potentially a hybrid of both. So we should ensure that backup disks and all other forms of long term storage at the datacenter are encrypted. If that's not supported by the specific storage service we're using in the cloud, we also have the option of using an out-of-band encryption mechanism. We should also implement asset tracking and asset management solutions during this phase. For example, we have to think about decommissioning of items like smartphones that might have had data or access to data available through them. If we're going to consider archive storage in the cloud, then with cloud providers, we have to create an archive location. And in some cases, we might also be able to flag it as being encrypted.
The Management Services tabbed page is displayed in the Internet Explorer browser window. The page includes the ALERT and OPERATION LOGS tabs. The OPERATION LOGS tabbed page is active. The presenter navigates to the ALERT tabbed page, which includes the following drop-down list boxes: SUBSCRIPTION, SERVICE TYPE, ALERT STATUS, and SERVICE NAME.

He then expands the SERVICE TYPE drop-down list box to display the following options: All, Cloud Service, mobile service, SQL Databases, Storage, Stream Analytics, Virtual machine, and Web app.

The presenter opens the AWS Management Console tabbed page in the Internet Explorer browser window. The page displays the multiple categories of Amazon Web Services such as Compute, Storage & Content Delivery, and Administration & Security.

He then clicks the Glacier - Archive Storage in the Cloud option that is displayed under the Storage & Content Delivery category. As a result, the Glacier Management Console tabbed page is displayed in the browser window. The page includes the Get started button along with the Getting started guide link.

If we have sensitive data that we're storing in the cloud and we don't have an option with the cloud provider services to encrypt, we can also encrypt out of band. Here for example, I'm storing a sensitive document in a cloud storage location. So what I could do is use other encryption mechanisms for confidentiality reasons against that data. For example, if it's a Windows system, I could right-click the file or folder, go to Properties and under Advanced; I would have the option to encrypt. We have to make sure the file system in the cloud supported Microsoft encrypted file system. Otherwise, we might use third-party encryption. For example, I could right-click and I'm using a third-party encryption tool here where I would simply say to Encrypt that document. Now I've already provided a pass phrase, so it knows what to use to encrypt and secure that data. After data has been retained for a period of required time through archiving, it can then be safely destroyed permanently. We need to ensure that data is destroyed securely if we're talking about sensitive data. In the past, on-premises, we had the option of physically shredding or drilling holes through hard disk platters to make sure nobody could get to that sensitive data.
The Sample_Sensitive_Date.txt file is displayed in the Notepad editor window. The file includes the following text:

This is sensitive stuff!

The presenter closes the window and navigates to the Documents folder that is displayed under the OneDrive folder in File Explorer. The folder includes the Personal, Pictures, Stuff, and Work subfolders, and the Sample_Sesitive_Data.txt file. He then right-clicks the file to display a shortcut menu, which includes options such as Open, Print, Make available online-only, AxCrypt, Share with, Send to, and Properties. He then selects the Properties option.

As a result, the Sample_Sensitive_Data.txt Properties dialog box is displayed, which includes the General, Security, and Details tabs. The General tab is selected by default. He then clicks the Advanced button to open the Advanced Attributes dialog box. The dialog box includes the File attributes and Compress or Encrypt attributes sections. The file attributes section includes the following checkboxes: File is ready for archiving and Allow this file to have contents indexed in addition to file properties. The Compress or Encrypt attributes section includes the following checkboxes: Compress contents to save disk space and Encrypt content to secure data.

He then closes the dialog boxes and returns to the Documents folder. Next he right-clicks the Sample_Sensitive_Data.txt file and selects the AxCrypt option. He then selects the Encrypt suboption. As a result, the Sample_Sensitive_Data.txt file renames as Sample_Sensitive_Data-txt.axx.

But wiping disks, or physically destroying storage media, or even making sure there's some kind of crypto shredding taking place might not be an option with the public cloud provider. Often, with many public cloud providers, when we delete data, it's simply marked as been writable so nobody can get to it, and it gets written over very quickly, which makes it harder to recover in the future. In this video, we talked about mapping security measures to each phase of the data life cycle.

### Exercise: Controlling Access to Cloud Data

### Exercise Overview

In this exercise, you will describe methods of controlling access to data stored in the cloud. You need to consider access control, confidentiality, data at rest, and data transmissions. Now pause the video and think about each of these access control mechanisms for cloud data and then come back to view possible solutions.

### Solution

One way of controlling access to cloud data and applications is through multi-factor authentication. For example, aside from just username and password, which comprise single-factor authentication because they're both something we know, we might also require a PKI certificate to be installed on the device, and that certificate would have to be trusted to the app that we're connecting to in the cloud or we might use smart card authentication where we have to physically have the card and have knowledge of the PIN to make it usable. We might also consider the use of identity federation, whether it's on-premises, in the cloud, or a hybrid of both. Identity federation allows us to have a centralized identity store. And after successful authentication, user's devices or services would then be authorized to access specific resources. This way we don't have to deal with identities such as user accounts with each and every application. This way it's centralized.

We also need to think about cloud tenant isolation. This can be achieved on the cloud provider network using virtual networks that keep one cloud tenant from the other or shielded virtual machines. So we've got a boundary or an isolation at the virtual machine level. We should also consider data encryption, both when data is being transmitted to and from the cloud as well as when data is being stored in the cloud. And finally, we should consider cloud firewall configurations. Instead of hosting a firewall on-premises on our network, which is still always relevant, we can also in addition to that make that happen in the cloud.
